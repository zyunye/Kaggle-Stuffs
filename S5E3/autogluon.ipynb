{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "from pipeline import convert_cols, train_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_data_dir = \"AutogluonDataSaves\"\n",
    "\n",
    "if not os.path.isdir(ag_data_dir):\n",
    "    os.mkdir(ag_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_autogluon(\n",
    "    train_dset,\n",
    "    test_dset,\n",
    "    model_name,\n",
    "    saves_dir=None,\n",
    "    metric=\"roc_auc\",\n",
    "    models_dir=\"AutogluonModels\",\n",
    "    **kwargs,\n",
    "):\n",
    "    if saves_dir is None:\n",
    "        saves_dir = model_name\n",
    "\n",
    "    if not os.path.isdir(saves_dir):\n",
    "        os.mkdir(saves_dir)\n",
    "\n",
    "    return {\n",
    "        \"train_data\": train_dset,\n",
    "        \"test_data\": test_dset,\n",
    "        \"models_dir\": models_dir,\n",
    "        \"model_name\": model_name,\n",
    "        \"metric\": metric,\n",
    "        \"save_preds_name\": f\"{model_name}.csv\",\n",
    "        \"save_probas_name\": f\"{model_name}_probs.csv\",\n",
    "        \"feat_imps_save\": f\"{model_name}_importances.csv\",\n",
    "        **kwargs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Dataset Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\", index_col=\"id\")\n",
    "test_df = pd.read_csv(\"data/test.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: No 'rainfall' column found\n"
     ]
    }
   ],
   "source": [
    "TARGET_FEAT = \"rainfall\"\n",
    "\n",
    "train_df = convert_cols(train_df)\n",
    "test_df = convert_cols(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       14.29 GB / 31.93 GB (44.8%)\n",
      "Disk Space Avail:   445.68 GB / 1863.00 GB (23.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Warning: dtype UInt8 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'UInt8Dtype()' as a data type\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"d:\\Programming\\Workspaces\\Python3 Workspace\\Misc Data Analysis\\Kaggle Playground Competition\\S5E3\\AutogluonModels\\base\"\n",
      "Train Data Rows:    2190\n",
      "Train Data Columns: 11\n",
      "Label Column:       rainfall\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14634.40 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['day']\n",
      "\t\t('float', [])    : 10 | ['pressure', 'maxtemp', 'temperature', 'mintemp', 'dewpoint', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['day']\n",
      "\t\t('float', [])    : 10 | ['pressure', 'maxtemp', 'temperature', 'mintemp', 'dewpoint', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t11 features in original data used to generate 11 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1752, Val Rows: 438\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.8641\t = Validation score   (roc_auc)\n",
      "\t1.64s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.8646\t = Validation score   (roc_auc)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\t0.9096\t = Validation score   (roc_auc)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\t0.8997\t = Validation score   (roc_auc)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9028\t = Validation score   (roc_auc)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9072\t = Validation score   (roc_auc)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.9081\t = Validation score   (roc_auc)\n",
      "\t10.9s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9086\t = Validation score   (roc_auc)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9099\t = Validation score   (roc_auc)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.9062\t = Validation score   (roc_auc)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "d:\\Programming\\Languages\\Python Venvs\\data\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:00:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\Programming\\Languages\\Python Venvs\\data\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:00:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\Programming\\Languages\\Python Venvs\\data\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:00:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\Programming\\Languages\\Python Venvs\\data\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:00:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\t0.9025\t = Validation score   (roc_auc)\n",
      "\t2.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9079\t = Validation score   (roc_auc)\n",
      "\t4.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\t0.8846\t = Validation score   (roc_auc)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.381, 'CatBoost': 0.286, 'NeuralNetTorch': 0.19, 'ExtraTreesEntr': 0.095, 'LightGBMXT': 0.048}\n",
      "\t0.9222\t = Validation score   (roc_auc)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 25.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6490.8 rows/s (438 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\Programming\\Workspaces\\Python3 Workspace\\Misc Data Analysis\\Kaggle Playground Competition\\S5E3\\AutogluonModels\\base\")\n"
     ]
    }
   ],
   "source": [
    "RETRAIN = True\n",
    "train_data = TabularDataset(train_df)\n",
    "test_data = TabularDataset(test_df)\n",
    "\n",
    "models_dir = \"AutogluonModels\"\n",
    "model_name = \"base\"\n",
    "\n",
    "metric = \"roc_auc\"\n",
    "\n",
    "save_preds_name = \"base_ag.csv\"\n",
    "save_probas_name = \"base_ag_probas.csv\"\n",
    "\n",
    "feat_imps_save = \"base_imps.csv\"\n",
    "\n",
    "if RETRAIN:\n",
    "    predictor = TabularPredictor(\n",
    "        label=TARGET_FEAT, path=os.path.join(models_dir, model_name), eval_metric=metric\n",
    "    ).fit(train_data=train_data, num_gpus=1)\n",
    "else:\n",
    "    predictor = TabularPredictor.load(os.path.join(models_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9566936026936026,\n",
       " 'accuracy': 0.9009132420091325,\n",
       " 'balanced_accuracy': 0.8383164983164983,\n",
       " 'mcc': 0.7223862462328952,\n",
       " 'f1': 0.9360070775582424,\n",
       " 'precision': 0.9115450890292935,\n",
       " 'recall': 0.9618181818181818}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "2190    0.930488\n",
       "2191    0.939786\n",
       "2192    0.896915\n",
       "2193    0.085392\n",
       "2194    0.062865\n",
       "          ...   \n",
       "2915    0.929509\n",
       "2916    0.791402\n",
       "2917    0.919580\n",
       "2918    0.941110\n",
       "2919    0.872247\n",
       "Name: rainfall, Length: 730, dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = predictor.predict(test_data)\n",
    "test_probas = predictor.predict_proba(test_data, as_multiclass=False)\n",
    "\n",
    "test_preds.to_csv(os.path.join(ag_data_dir, save_preds_name))\n",
    "test_probas.to_csv(os.path.join(ag_data_dir, save_probas_name))\n",
    "test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 11 features using 2190 rows with 5 shuffle sets...\n",
      "\t8.46s\t= Expected runtime (1.69s per shuffle set)\n",
      "\t2.47s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0.141763</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>7.127421e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.156184</td>\n",
       "      <td>0.127341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunshine</th>\n",
       "      <td>0.042046</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>6.674810e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.049542</td>\n",
       "      <td>0.034551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewpoint</th>\n",
       "      <td>0.028898</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>2.029370e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.022083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.020211</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>6.485430e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.019854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>1.547493e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019563</td>\n",
       "      <td>0.008486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winddirection</th>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>4.451354e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>0.009786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>2.673410e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.007845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>5.210308e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.007335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintemp</th>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.921343e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.008241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>5.466742e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.007706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtemp</th>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1.181519e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.007849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance    stddev       p_value  n  p99_high   p99_low\n",
       "cloud            0.141763  0.007004  7.127421e-07  5  0.156184  0.127341\n",
       "sunshine         0.042046  0.003640  6.674810e-06  5  0.049542  0.034551\n",
       "dewpoint         0.028898  0.003310  2.029370e-05  5  0.035713  0.022083\n",
       "day              0.020211  0.000173  6.485430e-10  5  0.020567  0.019854\n",
       "humidity         0.014024  0.002690  1.547493e-04  5  0.019563  0.008486\n",
       "winddirection    0.010759  0.000472  4.451354e-07  5  0.011732  0.009786\n",
       "windspeed        0.010499  0.001289  2.673410e-05  5  0.013154  0.007845\n",
       "pressure         0.010468  0.001522  5.210308e-05  5  0.013601  0.007335\n",
       "mintemp          0.009477  0.000600  1.921343e-06  5  0.010713  0.008241\n",
       "temperature      0.009279  0.000764  5.466742e-06  5  0.010852  0.007706\n",
       "maxtemp          0.008146  0.000144  1.181519e-08  5  0.008443  0.007849"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = predictor.feature_importance(train_data)\n",
    "feature_importances.to_csv(os.path.join(ag_data_dir, feat_imps_save))\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Day Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\", index_col=\"id\")\n",
    "test_df = pd.read_csv(\"data/test.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: No 'rainfall' column found\n"
     ]
    }
   ],
   "source": [
    "TARGET_FEAT = \"rainfall\"\n",
    "\n",
    "train_df = convert_cols(train_df)\n",
    "test_df = convert_cols(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       10.56 GB / 31.93 GB (33.1%)\n",
      "Disk Space Avail:   445.63 GB / 1863.00 GB (23.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Warning: dtype UInt8 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'UInt8Dtype()' as a data type\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"d:\\Programming\\Workspaces\\Python3 Workspace\\Misc Data Analysis\\Kaggle Playground Competition\\S5E3\\AutogluonModels\\day_numerical\"\n",
      "Train Data Rows:    2190\n",
      "Train Data Columns: 11\n",
      "Label Column:       rainfall\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10794.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['pressure', 'maxtemp', 'temperature', 'mintemp', 'dewpoint', ...]\n",
      "\t\t('int', [])   :  1 | ['day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['pressure', 'maxtemp', 'temperature', 'mintemp', 'dewpoint', ...]\n",
      "\t\t('int', [])   :  1 | ['day']\n",
      "\t0.0s = Fit runtime\n",
      "\t11 features in original data used to generate 11 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1752, Val Rows: 438\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.8836\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.8869\t = Validation score   (roc_auc)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.9121\t = Validation score   (roc_auc)\n",
      "\t6.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.9035\t = Validation score   (roc_auc)\n",
      "\t2.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9068\t = Validation score   (roc_auc)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9068\t = Validation score   (roc_auc)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.9134\t = Validation score   (roc_auc)\n",
      "\t16.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9115\t = Validation score   (roc_auc)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9059\t = Validation score   (roc_auc)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9149\t = Validation score   (roc_auc)\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "d:\\Programming\\Languages\\Python Venvs\\data\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:00:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\Programming\\Languages\\Python Venvs\\data\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:00:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\t0.9013\t = Validation score   (roc_auc)\n",
      "\t2.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9164\t = Validation score   (roc_auc)\n",
      "\t4.94s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.8845\t = Validation score   (roc_auc)\n",
      "\t8.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'CatBoost': 0.429, 'KNeighborsDist': 0.286, 'NeuralNetTorch': 0.286}\n",
      "\t0.9254\t = Validation score   (roc_auc)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 44.43s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 19040.5 rows/s (438 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\Programming\\Workspaces\\Python3 Workspace\\Misc Data Analysis\\Kaggle Playground Competition\\S5E3\\AutogluonModels\\day_numerical\")\n"
     ]
    }
   ],
   "source": [
    "RETRAIN = True\n",
    "\n",
    "train_data = TabularDataset(train_df)\n",
    "test_data = TabularDataset(test_df)\n",
    "\n",
    "models_dir = \"AutogluonModels\"\n",
    "model_name = \"day_numerical\"\n",
    "\n",
    "metric = \"roc_auc\"\n",
    "\n",
    "save_preds_name = f\"{model_name}.csv\"\n",
    "save_probas_name = f\"{model_name}_probs.csv\"\n",
    "\n",
    "feat_imps_save = f\"{model_name}_importances.csv\"\n",
    "\n",
    "if RETRAIN:\n",
    "    predictor = TabularPredictor(\n",
    "        label=TARGET_FEAT, path=os.path.join(models_dir, model_name), eval_metric=metric\n",
    "    ).fit(train_data=train_data, num_gpus=1)\n",
    "else:\n",
    "    predictor = TabularPredictor.load(os.path.join(models_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9825881032547699,\n",
       " 'accuracy': 0.9374429223744293,\n",
       " 'balanced_accuracy': 0.888097643097643,\n",
       " 'mcc': 0.8273167001231257,\n",
       " 'f1': 0.9595750958984951,\n",
       " 'precision': 0.9350201265094882,\n",
       " 'recall': 0.9854545454545455}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "2190    0.993326\n",
       "2191    0.994826\n",
       "2192    0.958189\n",
       "2193    0.207794\n",
       "2194    0.058902\n",
       "          ...   \n",
       "2915    0.992182\n",
       "2916    0.931664\n",
       "2917    0.988348\n",
       "2918    0.993542\n",
       "2919    0.940876\n",
       "Name: rainfall, Length: 730, dtype: float32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = predictor.predict(test_data)\n",
    "test_probas = predictor.predict_proba(test_data, as_multiclass=False)\n",
    "\n",
    "test_preds.to_csv(os.path.join(ag_data_dir, save_preds_name))\n",
    "test_probas.to_csv(os.path.join(ag_data_dir, save_probas_name))\n",
    "test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 11 features using 2190 rows with 5 shuffle sets...\n",
      "\t2.16s\t= Expected runtime (0.43s per shuffle set)\n",
      "\t0.77s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0.202862</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>2.242631e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218312</td>\n",
       "      <td>0.187411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.062283</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>9.544971e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.055466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winddirection</th>\n",
       "      <td>0.057888</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>6.285649e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.054681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewpoint</th>\n",
       "      <td>0.034249</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>1.158865e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038184</td>\n",
       "      <td>0.030314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>1.072646e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.036657</td>\n",
       "      <td>0.029232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.026457</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>1.393701e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029641</td>\n",
       "      <td>0.023273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunshine</th>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>8.249373e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.028209</td>\n",
       "      <td>0.019281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>0.023662</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>1.270651e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026444</td>\n",
       "      <td>0.020880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtemp</th>\n",
       "      <td>0.020763</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>5.595029e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.022751</td>\n",
       "      <td>0.018775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintemp</th>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>1.191912e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021608</td>\n",
       "      <td>0.017126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>0.018183</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>4.104369e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>0.015314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance    stddev       p_value  n  p99_high   p99_low\n",
       "cloud            0.202862  0.007504  2.242631e-07  5  0.218312  0.187411\n",
       "day              0.062283  0.003311  9.544971e-07  5  0.069100  0.055466\n",
       "winddirection    0.057888  0.001558  6.285649e-08  5  0.061096  0.054681\n",
       "dewpoint         0.034249  0.001911  1.158865e-06  5  0.038184  0.030314\n",
       "windspeed        0.032945  0.001803  1.072646e-06  5  0.036657  0.029232\n",
       "humidity         0.026457  0.001546  1.393701e-06  5  0.029641  0.023273\n",
       "sunshine         0.023745  0.002168  8.249373e-06  5  0.028209  0.019281\n",
       "pressure         0.023662  0.001351  1.270651e-06  5  0.026444  0.020880\n",
       "maxtemp          0.020763  0.000966  5.595029e-07  5  0.022751  0.018775\n",
       "mintemp          0.019367  0.001088  1.191912e-06  5  0.021608  0.017126\n",
       "temperature      0.018183  0.001393  4.104369e-06  5  0.021051  0.015314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = predictor.feature_importance(train_data)\n",
    "feature_importances.to_csv(os.path.join(ag_data_dir, feat_imps_save))\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series with KMeans Cluster IDs Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"data/train.csv\", index_col=\"id\")\n",
    "# test_df = pd.read_csv(\"data/test.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix the one test row with a nan value in winddirection\n",
    "# test_df.loc[test_df.isna().any(axis=1), \"winddirection\"] = np.median(\n",
    "#     train_df[train_df[\"day\"] == 153][\"winddirection\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET_FEAT = \"rainfall\"\n",
    "# TIME_COL = \"day\"\n",
    "\n",
    "# train_df = convert_cols(train_df)\n",
    "# test_df = convert_cols(test_df)\n",
    "\n",
    "# kmeans = train_kmeans(train_df.drop(columns=[\"rainfall\"]), n_clusters=3)\n",
    "\n",
    "# train_df[\"cluster_id\"] = kmeans.predict(train_df.drop(columns=[\"rainfall\"]))\n",
    "# test_df[\"cluster_id\"] = kmeans.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix some mislabeled days\n",
    "# train_df[\"expected_day\"] = (train_df.index) % 365 + 1\n",
    "# train_df[\"day_mislabeled\"] = train_df[\"day\"] != train_df[\"expected_day\"]\n",
    "# train_df.loc[train_df[\"day_mislabeled\"], \"day\"] = train_df.loc[\n",
    "#     train_df[\"day_mislabeled\"], \"expected_day\"\n",
    "# ]\n",
    "\n",
    "# train_df = train_df.drop(columns=[\"day_mislabeled\", \"expected_day\"])\n",
    "\n",
    "# # Create artificial years for time series analysis\n",
    "# train_df[\"year\"] = train_df.index // 365\n",
    "# train_df[\"year\"] += 1\n",
    "# test_df[\"year\"] = test_df.index // 365\n",
    "# test_df[\"year\"] += 1\n",
    "\n",
    "# # Create artificial datetime col\n",
    "# train_df[\"date\"] = pd.to_datetime(\n",
    "#     (train_df[\"year\"] + 1970).astype(str)\n",
    "# ) + pd.to_timedelta(train_df[\"day\"] - 1, unit=\"D\")\n",
    "# test_df[\"date\"] = pd.to_datetime(\n",
    "#     (test_df[\"year\"] + 1970).astype(str)\n",
    "# ) + pd.to_timedelta(test_df[\"day\"] - 1, unit=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.drop(columns=[\"day\", \"year\"])\n",
    "# test_df = test_df.drop(columns=[\"day\", \"year\"])\n",
    "\n",
    "# train_df = train_df.set_index([train_df.index, \"date\"])\n",
    "# test_df = test_df.set_index([test_df.index, \"date\"])\n",
    "\n",
    "# train_df = train_df.rename(columns={\"rainfall\":\"target\"})\n",
    "# test_df = test_df.rename(columns={\"rainfall\":\"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_static_df = train_df[\"cluster_id\"].reset_index().drop(columns=[\"date\"])\n",
    "# test_static_df = test_df[\"cluster_id\"].reset_index().drop(columns=[\"date\"])\n",
    "# train_static_df[\"id\"] = 0\n",
    "# test_static_df[\"id\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.reset_index()\n",
    "# test_df = test_df.reset_index()\n",
    "# train_df[\"id\"] = 0\n",
    "# test_df[\"id\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ts_df = TimeSeriesDataFrame.from_data_frame(\n",
    "#     train_df.drop(columns=[\"cluster_id\"]),\n",
    "#     id_column=\"id\",\n",
    "#     timestamp_column=\"date\",\n",
    "#     static_features_df=train_static_df,\n",
    "# )\n",
    "# test_ts_df = TimeSeriesDataFrame.from_data_frame(\n",
    "#     test_df.drop(columns=[\"cluster_id\"]),\n",
    "#     id_column=\"id\",\n",
    "#     timestamp_column=\"date\",\n",
    "#     static_features_df=test_static_df,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_len = 30\n",
    "# train_data, test_data = train_ts_df[:-prediction_len], train_ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.convert_frequency(freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_params = setup_autogluon(\n",
    "#     train_df, test_df, \"time_series_kmeans\", saves_dir=os.path.join(ag_data_dir, \"time_series_kmeans\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRAIN = True\n",
    "\n",
    "# if RETRAIN:\n",
    "#     predictor = TimeSeriesPredictor(\n",
    "#         prediction_length=prediction_len,\n",
    "#         eval_metric=\"MASE\",\n",
    "#         path=os.path.join(\n",
    "#             predictor_params[\"models_dir\"], predictor_params[\"model_name\"]\n",
    "#         ),\n",
    "#     ).fit(train_data=train_data.convert_frequency(freq=\"D\"))\n",
    "# else:\n",
    "#     predictor = TimeSeriesPredictor.load(os.path.join(models_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds = predictor.predict(test_data)\n",
    "# test_probas = predictor.predict_proba(test_data, as_multiclass=False)\n",
    "\n",
    "# test_preds.to_csv(os.path.join(ag_data_dir, save_preds_name))\n",
    "# test_probas.to_csv(os.path.join(ag_data_dir, save_probas_name))\n",
    "# test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances = predictor.feature_importance(train_data)\n",
    "# feature_importances.to_csv(os.path.join(ag_data_dir, feat_imps_save))\n",
    "\n",
    "# feature_importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
