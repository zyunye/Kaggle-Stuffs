{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\", index_col=\"id\")\n",
    "test_df = pd.read_csv(\"data/test.csv\", index_col=\"id\")\n",
    "\n",
    "train_extra_df = pd.read_csv(\"data/training_extra.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cols(df, cat_feats):\n",
    "    for feat in cat_feats:\n",
    "        df[feat] = df[feat].astype(\"category\")\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "CONT_FEATS = [\"Compartments\", \"Weight Capacity (kg)\"]\n",
    "CAT_FEATS = [name for name in train_df.columns.to_list() if name not in CONT_FEATS and name != \"Price\"]\n",
    "TARGET_FEAT = \"Price\"\n",
    "\n",
    "train_df = convert_cols(train_df, CAT_FEATS)\n",
    "test_df = convert_cols(test_df, CAT_FEATS)\n",
    "train_extra_df = convert_cols(train_extra_df, CAT_FEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels\\base\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.97 GB / 31.93 GB (59.4%)\n",
      "Disk Space Avail:   449.10 GB / 1863.00 GB (24.1%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"d:\\Programming\\Workspaces\\Python3 Workspace\\Misc Data Analysis\\Kaggle Playground Competition\\S5E2\\AutogluonModels\\base\\ds_sub_fit\\sub_fit_ho\"\n",
      "Warning: Exception encountered during DyStack sub-fit:\n",
      "\tNo models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t13s\t = DyStack   runtime |\t3587s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3587s\n",
      "AutoGluon will save models to \"d:\\Programming\\Workspaces\\Python3 Workspace\\Misc Data Analysis\\Kaggle Playground Competition\\S5E2\\AutogluonModels\\base\"\n",
      "Train Data Rows:    300000\n",
      "Train Data Columns: 9\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19105.30 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.58 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 7 | ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', ...]\n",
      "\t\t('float', [])    : 2 | ['Compartments', 'Weight Capacity (kg)']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 7 | ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', ...]\n",
      "\t\t('float', [])    : 2 | ['Compartments', 'Weight Capacity (kg)']\n",
      "\t0.3s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.58 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2390.20s of the 3586.19s of remaining time.\n",
      "\t-42.656\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2388.71s of the 3584.70s of remaining time.\n",
      "\t-47.2559\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2387.20s of the 3583.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.32%)\n",
      "\t-39.0134\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.85s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2354.10s of the 3550.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.32%)\n",
      "\t-39.0081\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.27s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 2326.69s of the 3522.68s of remaining time.\n",
      "\t-39.3138\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.58s\t = Training   runtime\n",
      "\t8.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2272.25s of the 3468.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.34%)\n",
      "\t-38.9962\t = Validation score   (-root_mean_squared_error)\n",
      "\t97.68s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 2172.43s of the 3368.42s of remaining time.\n",
      "\t-39.1898\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.89s\t = Training   runtime\n",
      "\t6.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2150.59s of the 3346.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.63%)\n",
      "\t-39.0099\t = Validation score   (-root_mean_squared_error)\n",
      "\t1014.82s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1133.50s of the 2329.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.61%)\n",
      "\t-39.0033\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.58s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1104.55s of the 2300.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.42%)\n",
      "\t-39.0215\t = Validation score   (-root_mean_squared_error)\n",
      "\t716.93s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 385.19s of the 1581.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.46%)\n",
      "\t-39.0149\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.87s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 339.89s of the 1535.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.40%)\n",
      "\t-39.0008\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.91s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 301.84s of the 1497.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.42%)\n",
      "\t-39.0367\t = Validation score   (-root_mean_squared_error)\n",
      "\t257.67s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 41.84s of the 1237.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.43%)\n",
      "\t-39.0089\t = Validation score   (-root_mean_squared_error)\n",
      "\t51.67s\t = Training   runtime\n",
      "\t3.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1183.27s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.6, 'XGBoost_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.12, 'LightGBM_BAG_L1': 0.04, 'RandomForestMSE_BAG_L1': 0.04}\n",
      "\t-38.9943\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1182.34s of the 1182.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.10%)\n",
      "\t-38.9909\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.9s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1142.87s of the 1142.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.09%)\n",
      "\t-38.9929\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.1s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 1109.25s of the 1109.17s of remaining time.\n",
      "\t-39.114\t = Validation score   (-root_mean_squared_error)\n",
      "\t453.91s\t = Training   runtime\n",
      "\t11.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 643.25s of the 643.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.11%)\n",
      "\t-38.994\t = Validation score   (-root_mean_squared_error)\n",
      "\t56.86s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 583.96s of the 583.88s of remaining time.\n",
      "\t-39.027\t = Validation score   (-root_mean_squared_error)\n",
      "\t54.12s\t = Training   runtime\n",
      "\t9.59s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 519.58s of the 519.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.93%)\n",
      "\t-38.9974\t = Validation score   (-root_mean_squared_error)\n",
      "\t400.69s\t = Training   runtime\n",
      "\t1.68s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 116.30s of the 116.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.49%)\n",
      "\t-38.9945\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.37s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 83.36s of the 83.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.02%)\n",
      "\t-39.0344\t = Validation score   (-root_mean_squared_error)\n",
      "\t93.76s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -13.20s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.24, 'LightGBMXT_BAG_L2': 0.2, 'NeuralNetFastAI_BAG_L2': 0.2, 'XGBoost_BAG_L2': 0.12, 'CatBoost_BAG_L1': 0.08, 'LightGBM_BAG_L2': 0.08, 'RandomForestMSE_BAG_L2': 0.08}\n",
      "\t-38.9803\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3601.11s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2022.8 rows/s (37500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\Programming\\Workspaces\\Python3 Workspace\\Misc Data Analysis\\Kaggle Playground Competition\\S5E2\\AutogluonModels\\base\")\n"
     ]
    }
   ],
   "source": [
    "RETRAIN = True\n",
    "train_data = TabularDataset(train_df)\n",
    "test_data = TabularDataset(test_df)\n",
    "\n",
    "models_dir = \"AutogluonModels\"\n",
    "model_name = \"base\"\n",
    "\n",
    "metric = \"root_mean_squared_error\"\n",
    "\n",
    "\n",
    "if RETRAIN:\n",
    "    predictor = TabularPredictor(\n",
    "        label=TARGET_FEAT, \n",
    "        path=os.path.join(models_dir, model_name), \n",
    "        eval_metric=metric).fit(\n",
    "            train_data=train_data, \n",
    "            presets=\"best_quality\",\n",
    "            ag_args_fit={\"num_gpus\":1})\n",
    "else:\n",
    "    predictor = TabularPredictor.load(os.path.join(models_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -38.49682012537276,\n",
       " 'mean_squared_error': -1482.005159765305,\n",
       " 'mean_absolute_error': -33.31073795959358,\n",
       " 'r2': 0.027597154069714858,\n",
       " 'pearsonr': 0.28052697509831,\n",
       " 'median_absolute_error': -33.365060474853514}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_data_dir = \"AutogluonDataSaves\"\n",
    "\n",
    "if not os.path.isdir(ag_data_dir):\n",
    "    os.mkdir(ag_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "300000    81.038185\n",
       "300001    83.754807\n",
       "300002    83.539169\n",
       "300003    81.186523\n",
       "300004    79.426109\n",
       "            ...    \n",
       "499995    80.201431\n",
       "499996    78.026917\n",
       "499997    82.367645\n",
       "499998    79.322334\n",
       "499999    81.349251\n",
       "Name: Price, Length: 200000, dtype: float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = predictor.predict(test_data)\n",
    "\n",
    "test_preds.to_csv(os.path.join(ag_data_dir, \"base.csv\"))\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 9 features using 5000 rows with 5 shuffle sets...\n",
      "\t208.59s\t= Expected runtime (41.72s per shuffle set)\n",
      "\t88.64s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "      <td>0.561485</td>\n",
       "      <td>0.017058</td>\n",
       "      <td>1.021065e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.596609</td>\n",
       "      <td>0.526362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compartments</th>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.018580</td>\n",
       "      <td>5.722636e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.435556</td>\n",
       "      <td>0.359044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color</th>\n",
       "      <td>0.081503</td>\n",
       "      <td>0.012299</td>\n",
       "      <td>6.037601e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.106826</td>\n",
       "      <td>0.056179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Material</th>\n",
       "      <td>0.077238</td>\n",
       "      <td>0.017175</td>\n",
       "      <td>2.749905e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.112601</td>\n",
       "      <td>0.041875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brand</th>\n",
       "      <td>0.046120</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>4.719430e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059582</td>\n",
       "      <td>0.032658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size</th>\n",
       "      <td>0.028262</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>3.590287e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.053979</td>\n",
       "      <td>0.002546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Style</th>\n",
       "      <td>0.016524</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>7.598027e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.011081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waterproof</th>\n",
       "      <td>0.013758</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>1.011348e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.055330</td>\n",
       "      <td>-0.027815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <td>-0.002289</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>6.926187e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>-0.021633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance    stddev       p_value  n  p99_high  \\\n",
       "Weight Capacity (kg)    0.561485  0.017058  1.021065e-07  5  0.596609   \n",
       "Compartments            0.397300  0.018580  5.722636e-07  5  0.435556   \n",
       "Color                   0.081503  0.012299  6.037601e-05  5  0.106826   \n",
       "Material                0.077238  0.017175  2.749905e-04  5  0.112601   \n",
       "Brand                   0.046120  0.006538  4.719430e-05  5  0.059582   \n",
       "Size                    0.028262  0.012490  3.590287e-03  5  0.053979   \n",
       "Style                   0.016524  0.002643  7.598027e-05  5  0.021967   \n",
       "Waterproof              0.013758  0.020190  1.011348e-01  5  0.055330   \n",
       "Laptop Compartment     -0.002289  0.009394  6.926187e-01  5  0.017054   \n",
       "\n",
       "                       p99_low  \n",
       "Weight Capacity (kg)  0.526362  \n",
       "Compartments          0.359044  \n",
       "Color                 0.056179  \n",
       "Material              0.041875  \n",
       "Brand                 0.032658  \n",
       "Size                  0.002546  \n",
       "Style                 0.011081  \n",
       "Waterproof           -0.027815  \n",
       "Laptop Compartment   -0.021633  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = predictor.feature_importance(train_data)\n",
    "feature_importances.to_csv(os.path.join(ag_data_dir, \"feat_imps.csv\"))\n",
    "\n",
    "feature_importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
